---
layout: post
title: HDFS 写数据异常
---

集群一共五个 DataNode，前三台内存小硬盘大，写 HDFS 的程序部署在后面两台机器上，内存大硬盘小。

程序写 HDFS 关闭句柄失败，DataNode 也能看到相对于的错误日志：`DataXceiver error processing WRITE_BLOCK operationf`

经过排查，发现整个集群的存储空间还有很大，只用了 15% 左右，但是数据倾斜比较严重，前三台机器硬盘可用空间很大，但是后面两台机器几乎被写满。
```shell
hdfs dfsamdin -report
```

先停掉了写文件的程序，手动平衡 HDFS 机器的数据块
```shell
# 查看 hdfs 设置的网络传输限制，并调大至 800000000 byte
hdfs dfsadmin -getBalancerBandwidth `hostname`:8010
hdfs dfsadmin -setBalancerBandwidth 800000000

# 手动平衡 hdfs 数据块，平衡至各个 DataNode 硬盘使用率在 20% 以内
hdfs balancer -threshold 20
```

balancer 在如下5种情况下会自动退出：
- 集群已达到均衡状态；
- 没有 block 能被移动；
- 连续 5 次迭代移动没有任何一个 block 被移动；
- 当与 NameNode 交互式出现了 IOException；
- 另一个 balancer 在运行中。

平衡完成后，程序已经可以正常写入不会报错了，但是问题还没有完全解决，还需要做以下调整：
- 设置好 HDFS 自动平衡机制
- 计算每天写入的数据量，设置定时任务，定期删除旧数据，使得 HDFS 的数据总量保持在 80% 以内

如此才能保证集群的数据总量不会写满硬盘，并留有余地，且数据倾斜保持在一个合理的范围以内
